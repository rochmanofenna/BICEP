{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPp7WU+D3Zg/Fx9s5iu9bi/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rochmanofenna/BICEP/blob/main/triton_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "pip uninstall -y torch torchvision torchaudio triton cupy-cuda118 || true\n",
        "\n",
        "# 2. Install PyTorch nightly for CUDA 12.5\n",
        "pip install --pre torch torchvision torchaudio \\\n",
        "    --extra-index-url https://download.pytorch.org/whl/nightly/cu125\n",
        "\n",
        "# 3. Install Triton and CuPy matching CUDA 12.x\n",
        "pip install --quiet triton==3.3.1 cupy-cuda12x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO-oU1U6IOY6",
        "outputId": "7ff31b37-554c-49b4-f5e2-6d59e0f7991d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.7.1\n",
            "Uninstalling torch-2.7.1:\n",
            "  Successfully uninstalled torch-2.7.1\n",
            "Found existing installation: torchvision 0.22.1\n",
            "Uninstalling torchvision-0.22.1:\n",
            "  Successfully uninstalled torchvision-0.22.1\n",
            "Found existing installation: torchaudio 2.7.1\n",
            "Uninstalling torchaudio-2.7.1:\n",
            "  Successfully uninstalled torchaudio-2.7.1\n",
            "Found existing installation: triton 3.3.1\n",
            "Uninstalling triton-3.3.1:\n",
            "  Successfully uninstalled triton-3.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/nightly/cu125\n",
            "Collecting torch\n",
            "  Using cached torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Using cached torchaudio-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch) (1.11.1.6)\n",
            "Collecting triton==3.3.1 (from torch)\n",
            "  Using cached triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Using cached torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n",
            "Using cached triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "Using cached torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "Using cached torchaudio-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "Installing collected packages: triton, torch, torchvision, torchaudio\n",
            "Successfully installed torch-2.7.1 torchaudio-2.7.1 torchvision-0.22.1 triton-3.3.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping cupy-cuda118 as it is not installed.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, triton, cupy\n",
        "print(\"GPU:       \", torch.cuda.get_device_name(0))\n",
        "print(\"Torch CUDA:\", torch.version.cuda, \"   Triton:\", triton.__version__)\n",
        "print(\"CuPy device:\", cupy.cuda.runtime.getDeviceProperties(0)[\"name\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD3WXSFRIPU2",
        "outputId": "33e2806e-8105-4cce-c097-6249fd8a3744"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU:        NVIDIA A100-SXM4-40GB\n",
            "Torch CUDA: 12.6    Triton: 3.3.1\n",
            "CuPy device: b'NVIDIA A100-SXM4-40GB'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git clone --depth 1 https://github.com/rochmanofenna/mismatch-trading.git\n",
        "cd mismatch-trading"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As_ro6YqIQK_",
        "outputId": "489f6581-31fa-42bc-b80d-2c8d77f7d7e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "fatal: destination path 'mismatch-trading' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import triton\n",
        "import triton.language as tl\n",
        "import torch\n",
        "import time\n",
        "\n",
        "# 4.1) Define a minimal “just RNG + cumsum” kernel\n",
        "@triton.jit\n",
        "def fused_sde_stub(path_ptr, n_steps, stride, T, directional_bias):\n",
        "    pid  = tl.program_id(0)\n",
        "    path = path_ptr + pid * stride\n",
        "    dt   = T / n_steps\n",
        "    acc  = tl.load(path)\n",
        "    for i in range(n_steps):\n",
        "        rnd = tl.randn(seed=pid, offset=i)\n",
        "        acc += rnd * tl.sqrt(dt)\n",
        "        tl.store(path + i + 1, acc)\n",
        "\n",
        "# 4.2) Host setup & benchmark\n",
        "n_paths, n_steps = 1024, 1000\n",
        "stride = n_steps + 1\n",
        "paths  = torch.zeros((n_paths, stride), device='cuda', dtype=torch.float32)\n",
        "grid   = (n_paths,)\n",
        "\n",
        "# warm-up compile\n",
        "fused_sde_stub[grid](paths, n_steps, stride, 1.0, 0.0)\n",
        "\n",
        "# measure\n",
        "t0 = time.time()\n",
        "for _ in range(100):\n",
        "    fused_sde_stub[grid](paths, n_steps, stride, 1.0, 0.0)\n",
        "print(\"Stub avg time:\", (time.time() - t0)/100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5OD2OtfIRMh",
        "outputId": "65db84be-f0e7-4071-ef33-8c6a27bba55b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stub avg time: 2.5968551635742188e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1) Fuse in your apply_stochastic_controls math\n",
        "@triton.jit\n",
        "def fused_sde_control(path_ptr, n_steps, stride, T,\n",
        "                      feedback, decay, hi_th, lo_th,\n",
        "                      total_steps, base_var):\n",
        "    pid  = tl.program_id(0)\n",
        "    path = path_ptr + pid * stride\n",
        "    dt   = T / n_steps\n",
        "    acc  = tl.load(path)\n",
        "\n",
        "    for i in range(n_steps):\n",
        "        rnd = tl.randn(seed=pid, offset=i)\n",
        "\n",
        "        # simplified control_randomness_by_state\n",
        "        norm = 1.0 / total_steps\n",
        "        f1   = tl.where(norm < lo_th,\n",
        "                        1.5,\n",
        "                        tl.where(norm > hi_th, 0.5, 1.0))\n",
        "        t   = i * dt\n",
        "        vf  = base_var * f1 * tl.exp(-decay * t)\n",
        "        # clamp(0.5 + feedback*0.5, 0.2, 1.0)\n",
        "        tmp    = 0.5 + feedback * 0.5\n",
        "        scale2 = tl.maximum(tl.minimum(tmp, 1.0), 0.2)\n",
        "\n",
        "        inc = rnd * tl.sqrt(dt) * scale2 * vf\n",
        "        acc += inc\n",
        "        tl.store(path + i + 1, acc)\n",
        "\n",
        "# 5.2) Benchmark\n",
        "# (reuse paths, grid from above)\n",
        "fused_sde_control[grid](\n",
        "    paths, n_steps, stride, 1.0,\n",
        "    0.5, 0.1, 10.0, 2.0,\n",
        "    float(n_steps), 1.0\n",
        ")\n",
        "t0 = time.time()\n",
        "for _ in range(100):\n",
        "    fused_sde_control[grid](\n",
        "        paths, n_steps, stride, 1.0,\n",
        "        0.5, 0.1, 10.0, 2.0,\n",
        "        float(n_steps), 1.0\n",
        "    )\n",
        "print(\"Control avg time:\", (time.time() - t0)/100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlCGPUWQIShX",
        "outputId": "bcb07d07-e54c-47c6-9855-31324f78f06b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Control avg time: 3.020763397216797e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install ninja-build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRRHeVm3NJxv",
        "outputId": "6fc51fe6-e6bc-4f41-a1dd-0c1100cfebdf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ninja-build is already the newest version (1.10.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKdT3gUqNTzR",
        "outputId": "f749bb3f-de17-429f-e730-feca8e9d3c2e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mismatch-trading  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export CUDA_HOME=/usr/local/cuda-11.8\n",
        "!export PATH=$CUDA_HOME/bin:$PATH"
      ],
      "metadata": {
        "id": "7qYVjQRPUjgS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "rm -rf /root/.cache/torch_extensions"
      ],
      "metadata": {
        "id": "qdSzV1evZOWM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# throw away any half‐built cruft:\n",
        "rm -rf /root/.cache/torch_extensions"
      ],
      "metadata": {
        "id": "TwMfdbxHqdjW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd mismatch-trading/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1HTc6CYVYtQ",
        "outputId": "44dc9ac1-b641-4cd9-f91f-7fde499bfaf1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'mismatch-trading/'\n",
            "/content/mismatch-trading\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.cpp_extension import load\n",
        "\n",
        "# (no need to pre‐mkdir build_directory if you omit that argument)\n",
        "sde_ext = load(\n",
        "    name=\"sde_ext\",\n",
        "    sources=[\n",
        "      \"backends/bicep/sde_int/curand_kernel.cu\",\n",
        "      \"backends/bicep/sde_int/binding.cu\"\n",
        "    ],\n",
        "    extra_cuda_cflags=[\"-O3\",\"-I/usr/local/cuda/include\"],\n",
        "    extra_ldflags=[\"-lcurand\"],\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6SCcMmTjoPe",
        "outputId": "cc841c13-9bdf-4706-84fb-190573514d78"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py311_cu126 as PyTorch extensions root...\n",
            "The input conditions for extension module sde_ext have changed. Bumping to version 2 and re-building as sde_ext_v2...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py311_cu126/sde_ext/build.ninja...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module sde_ext_v2...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "Loading extension module sde_ext_v2...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, time\n",
        "\n",
        "# 1) Simulation parameters\n",
        "n_paths        = 1024\n",
        "n_steps        = 1000\n",
        "stride         = n_steps + 1\n",
        "\n",
        "# 2) Control-kernel parameters\n",
        "feedback_value = 0.5\n",
        "decay_rate     = 0.1\n",
        "high_threshold = 10.0\n",
        "low_threshold  = 2.0\n",
        "base_variance  = 1.0\n",
        "\n",
        "# 3) Allocate the paths tensor\n",
        "paths = torch.zeros((n_paths, stride),\n",
        "                    device='cuda',\n",
        "                    dtype=torch.float32)\n",
        "\n",
        "# 4) Warm up the extension (flush any JIT / CUDA overhead)\n",
        "for _ in range(10):\n",
        "    sde_ext.sde_curand(\n",
        "        paths, n_steps, stride,\n",
        "        1.0,           # T\n",
        "        feedback_value,\n",
        "        decay_rate,\n",
        "        high_threshold,\n",
        "        low_threshold,\n",
        "        float(n_steps),\n",
        "        base_variance\n",
        "    )\n",
        "\n",
        "# 5) Create and record CUDA events\n",
        "starter = torch.cuda.Event(enable_timing=True)\n",
        "ender   = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "starter.record()\n",
        "for _ in range(100):\n",
        "    sde_ext.sde_curand(\n",
        "        paths, n_steps, stride,\n",
        "        1.0,\n",
        "        feedback_value,\n",
        "        decay_rate,\n",
        "        high_threshold,\n",
        "        low_threshold,\n",
        "        float(n_steps),\n",
        "        base_variance\n",
        "    )\n",
        "ender.record()\n",
        "torch.cuda.synchronize()\n",
        "\n",
        "# 6) Report\n",
        "ms = starter.elapsed_time(ender) / 100\n",
        "print(f\"CURAND avg time: {ms:.4f} ms   ({1e6 * ms / n_steps:.1f} μs per path)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuY4EcvpvGNI",
        "outputId": "24fdbfcd-b314-4670-e283-36c6a3834c62"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CURAND avg time: 0.4961 ms   (496.1 μs per path)\n"
          ]
        }
      ]
    }
  ]
}